# Network Measure-Enriched Graph Neural Networks: A New Benchmark for Power Grid Stability Assessment

![NSGNN-viz](./NSGNN.png)

Can network measures enhance the predictive capability of Graph Neural Networks (GNNs) for the stability of power grids, and can they aid in the generalization of models to real-world networks?

The answer is affirmative. In our paper, we present, for the first time, a benchmark that analyzes 48 network measures within the context of GNN-based stability assessments, introducing two strategies for their integration into the GNN framework: NSGNN-F and NSGNN-S.

Our findings reveal that prioritizing measures with consistent distributions across different grids as inputs or treating measures as auxiliary supervised information significantly improves the modelâ€™s generalization ability to realistic grid topologies.

In this *NSGNN* package we provide several Network Measure encodings and GNN model choices, implementing for both NSGNN-F and NSGNN-S. One can easily try our model with different GNN layer or different combination of network measures. NSGNN is built based on [PyG](https://www.pyg.org/), [GraphGym](https://pytorch-geometric.readthedocs.io/en/2.0.0/notes/graphgym.html) from PyG2, and [GraphGPS](https://github.com/rampasek/GraphGPS). We thank them for providing the codes and tools.
Specifically *PyG v2.2* is required.

## Summary of 48 Network Measures
Summary of 48 network measures evaluated, categorized into Nodal and Global types and indexed serially. Each entry includes measure names or definitions with relevant citations.

### Nodal

<table>
  <thead>
    <tr>
      <th>Name / Definition</th>
      <th>Name / Definition</th>
      <th>Name / Definition</th>
      <th>Name / Definition</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0. injected power P</td>
      <td>1. AP</td>
      <td>2. AÂ²P</td>
      <td>3. AÂ³P</td>
    </tr>
    <tr>
      <td>4. betweenness centrality</td>
      <td>5. Katz centrality (<small>networkx</small>)</td>
      <td>6. degree centrality</td>
      <td>7. A&#x1D538;</td>
    </tr>
    <tr>
      <td>8. minimum neighbor degree</td>
      <td>9. maximum neighbor degree</td>
      <td>10. clustering coefficient</td>
      <td>11. AÂ² &#x1D538;</td>
    </tr>
    <tr>
      <td>12. closeness centrality</td>
      <td>13. load centrality (<small>networkx</small>)</td>
      <td>14. eigenvector centrality</td>
      <td>15. AÂ³ &#x1D538;</td>
    </tr>
    <tr>
      <td>16. second-order centrality (<small>networkx</small>)</td>
      <td>17. current-flow close centrality</td>
      <td>18. sparse sprout</td>
      <td>19. bulk</td>
    </tr>
    <tr>
      <td>20. harmonic centrality (<small>networkx</small>)</td>
      <td>21. square clustering (<small>networkx</small>)</td>
      <td>22. Fiedler eigenvector</td>
      <td>23. root</td>
    </tr>
    <tr>
      <td>24. resistance distance centrality</td>
      <td>25. current-flow betweenness centrality</td>
      <td>26. inner tree node</td>
      <td>27. proper leaf</td>
    </tr>
    <tr>
      <td>28. average neighbor degree</td>
      <td>29. connected to maximally loaded line</td>
      <td>30. degree assortativity</td>
      <td>31. graphlets</td>
    </tr>
    <tr>
      <td>32. average load of connected lines</td>
      <td>33. minimum load of connected lines</td>
      <td>34. P assortativity</td>
      <td>35. dense sprout</td>
    </tr>
    <tr>
      <td>36. random walk structural encoding</td>
      <td>37. maximum load of connected lines</td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>

### Global

<table>
  <thead>
    <tr>
      <th>Name / Definition</th>
      <th>Name / Definition</th>
      <th>Name / Definition</th>
      <th>Name / Definition</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>38. eccentricity (<small>networkx</small>)</td>
      <td>39. Kirchhoff index</td>
      <td>40. power sign ratio</td>
      <td>41. transitivity</td>
    </tr>
    <tr>
      <td>42. resistance distance Kirchhoff index</td>
      <td>43. inverse algebraic connectivity 1/&lambda;â‚‚</td>
      <td>44. eigenratio &lambda;â‚‚/&lambda;â‚™</td>
      <td>45. diameter</td>
    </tr>
    <tr>
      <td>46. maximal line load at operation point</td>
      <td>47. universal Kuramoto order parameter</td>
      <td></td>
      <td></td>
    </tr>
  </tbody>
</table>


## Python environment setup with Conda

```bash
conda create -n nsgnn python=3.10
conda activate nsgnn

conda install pytorch=1.13 torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
conda install pyg=2.2 -c pyg -c conda-forge
pip install pyg-lib -f https://data.pyg.org/whl/torch-1.13.0+cu117.html

conda install openbabel fsspec rdkit -c conda-forge

pip install pytorch-lightning yacs torchmetrics
pip install tensorboardX
pip install ogb

conda clean --all
```

## Datasets

Our datasets are available on the drive and will be downloaded automatically when you execute our project. Our datasets including **dataset20**, **dataset100**, **Texas**, **Spain**, **Germany**, and **France** power grids.
<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Dataset</th>
      <th>Graphs</th>
      <th>Total Nodes</th>
      <th>Total Edges</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="2"><strong>SYN</strong></td>
      <td>Dataset20</td>
      <td>10,000</td>
      <td>200,000</td>
      <td>538,188</td>
    </tr>
    <tr>
      <td>Dataset100</td>
      <td>10,000</td>
      <td>1,000,000</td>
      <td>2,857,882</td>
    </tr>
    <tr>
      <td rowspan="4"><strong>Real / Realistic</strong></td>
      <td>Texas</td>
      <td>1</td>
      <td>1,910</td>
      <td>5,154</td>
    </tr>
    <tr>
      <td>France</td>
      <td>1</td>
      <td>146</td>
      <td>446</td>
    </tr>
    <tr>
      <td>Germany</td>
      <td>1</td>
      <td>438</td>
      <td>1,324</td>
    </tr>
    <tr>
      <td>Spain</td>
      <td>1</td>
      <td>98</td>
      <td>350</td>
    </tr>
  </tbody>
</table>

### Data pre-processing 
*(executed automatically by `master_loader.py` if `processed/` is absent).*

| Step | What happens | Code entry-point |
|------|--------------|------------------|
| 1    | **Read raw files** (`grid_data_*.h5`, `snbs_*.h5`, 48-measure CSV, graphlet CSV) | â€” |
| 2    | **Parse & align** node / edge tensors, SNBS labels, network measures, graphlets | `power_grid_data.py` |
| 3    | **Build PyG `Data`** objects: `x = [P \| Netsci \| Graphlets]`, `edge_index`, `edge_attr`, `y` | `power_grid_data.py` |
| 4    | **Create splits** and save `train.pt / valid.pt / test.pt` | `master_loader.py::join_dataset_splits` |

Processed files land in datasets/Texas/processed/.
After that, YAML config strores the dataset path and other parameters used by the model.

## Running NSGNN-F
```bash
conda activate nsgnn

# Running NSGNN-F with GraphSAGE layer and random walk structural encoding for training on dataset20 and testing on Texas.
python main.py --cfg configs/NSGNN-F/SAGE-F-tr20teTexas-NRWSE.yaml

# Running NSGNN-F with TAGCN layer and the combination of measures encoding for training on dataset20 and testing on Texas.
python main.py --cfg configs/NSGNN-F/TAGCN-F-tr20teTexas-NetSci.yaml

# Running NSGNN-F with TAGCN layer and random walk structural encoding for training on dataset20 and testing on Texas.
python main.py --cfg configs/NSGNN-F/TAGCN-F-tr20teTexas-NRWSE.yaml

#Running NSGNN-F for only inference.
python main.py --cfg tests/NSGNN-F/TAGCN-F-tr100teTexas-NRWSE-inference.yaml
```

## Running NSGNN-S
```bash
conda activate nsgnn
# Running NSGNN-S with ARMA layer with random walk structural encoding
python main.py --cfg configs/NSGNN-S/ARMA-S-tr100teTexas-NRWSE.yaml

# Running NSGNN-S with TAGCN layer with random walk structural encoding
python main.py --cfg configs/NSGNN-S/TAGCN-S-tr100teTexas-NRWSE.yaml
```

## Hyperparameter Tuning 
All experiment settings live in a single and readable **YAML** file (see
`configs/NSGNN-F/TAGCN-F-tr20teTexas-NRWSE.yaml`, excerpt below).  
Feel free to edit it and re-launch `main.py`.

Key settings you may want to tune:

| Group                      | Field | Description |
|----------------------------|-------|-------------|
| **Model depth / width**    | `nsgnn.layers` | number of GNN layers (e.g. 6 â€“ 14) |
|                            | `nsgnn.dim_hidden` | hidden dimension per layer |
| **Regularization**         | `nsgnn.dropout` | feature-drop rate inside NSGNN |
|                            | `gnn.dropout` | MLP head dropout |
| **Optimiser**              | `optim.base_lr` | initial learning rate |
|                            | `optim.weight_decay` | L2 penalty |
| **Network-measure choice** | `Netsci_Graphlets.SelectedMetrics` | list of index IDs (0-47) to include; combine or ablate measures by editing this array |

To run a minimal example (e.g., tr20â†’Texas, TAGCN-F), one can use the following command:
```bash
python main.py --cfg configs/NSGNN-F/TAGCN-F-tr20teTexas-NRWSE.yaml
```

## Expected performance

Performance comparison of SNBS prediction methods, quantified by the $R^2$ score in %. The table highlights the top results with emojis:
- ðŸ¥‡ **First Place**
- ðŸ¥ˆ **Second Place**
- ðŸ¥‰ **Third Place**

| **Model** | **Method**             | **tr20te100**       | **Tr20 Test Texas**   | **Tr20 Test France**   | **Tr20 Test Germany**  | **Tr20 Test Spain**    | **Tr100 Test Texas**    | **Tr100 Test France**  | **Tr100 Test Germany** | **Tr100 Test Spain**    |
|-----------|------------------------|---------------------|-----------------------|------------------------|------------------------|------------------------|-------------------------|------------------------|------------------------|-------------------------|
| **M1**    | GCN                    | 58.24Â±0.47          | 50.17Â±0.36            | 60.67Â±1.27             | 63.50Â±0.35             | 22.47Â±1.18             | 48.56Â±1.02              | 77.36Â±1.08             | 79.31Â±0.74             | 65.25Â±1.21              |
|           | GraphSAGE              | 48.93Â±0.87          | 25.83Â±0.42            | 60.25Â±2.53             | 34.18Â±2.93             | 9.03Â±3.44              | 62.95Â±4.12              | 78.63Â±1.32             | 73.84Â±1.68             | 71.00Â±1.25              |
|           | ARMA                   | 67.12Â±0.80          | 52.50Â±2.68            | 57.36Â±1.14             | 75.60Â±0.21             | 16.73Â±9.75             | 63.95Â±2.27              | 88.69Â±1.22             | 90.84Â±0.20             | 71.12Â±3.26              |
|           | TAGCN                  | 66.32Â±0.74          | 66.36Â±1.34            | 64.08Â±2.07             | 72.11Â±0.67             | 41.47Â±0.83             | 83.31Â±1.46              | 90.47Â±0.53             | 91.09Â±0.21             | 83.47Â±1.26              |
|           | GraphGPS               | 58.61Â±0.84          | 62.28Â±3.17            | 48.73Â±6.42             | 72.62Â±1.02             | 39.95Â±2.58             | 83.44Â±0.48              | 90.60Â±0.71             | 90.11Â±1.01             | 71.56Â±0.79              |
|           | EERM                   | 32.95Â±3.56          | 45.41Â±2.31            | 24.23Â±3.17             | 15.78Â±3.17             | 1.24Â±3.28              | 48.98Â±4.37              | 22.10Â±3.88             | 34.65Â±2.28             | 2.27Â±3.19               |
|           | GeneralGNN             | 67.69Â±2.15          | 72.46Â±1.76            | 70.42Â±1.85             | 68.23Â±2.16             | 63.65Â±2.16             | 80.78Â±1.21              | 82.17Â±1.37             | 82.39Â±1.28             | 64.08Â±1.85              |
| **M2**    | Logreg                 | &lt;0                | &lt;0                  | &lt;0                   | &lt;0                   | &lt;0                   | &lt;0                    | &lt;0                  | &lt;0                  | &lt;0                    |
|           | MLP                    | 46.45Â±0.65          | 8.84Â±5.53             | 29.12Â±4.66             | 10.48Â±3.11             | &lt;0                   | 26.51Â±2.31              | 65.79Â±1.26             | 44.76Â±1.50             | 36.51Â±2.22              |
|           | GBR                    | 53.82Â±0.00          | 17.36Â±0.00            | 46.20Â±0.00             | 6.02Â±0.00              | &lt;0                   | 26.84Â±1.08              | 69.09Â±0.14             | 59.04Â±0.97             | 27.43Â±1.03              |
|           | GBC                    | 57.02Â±0.09          | &lt;0                  | 44.91Â±0.66             | 11.76Â±0.64             | 13.26Â±2.12             | &lt;0                    | 63.45Â±2.10             | 40.41Â±0.17             | 42.53Â±1.70              |
| **Our**   | NSGNN-F&nbsp;(+RW)          | **ðŸ¥‡ 70.18Â±0.26**   | **ðŸ¥‡ 83.14Â±0.31**     | **ðŸ¥ˆ 77.88Â±0.70**      | **ðŸ¥ˆ 80.53Â±1.44**      | **ðŸ¥ˆ 75.68Â±1.53**      | **ðŸ¥‰ 90.36Â±1.04**        | **ðŸ¥‡ 91.69Â±0.50**      | **ðŸ¥ˆ 93.56Â±0.48**      | **ðŸ¥ˆ 92.10Â±1.18**        |
|           | NSGNN-F&nbsp;(+Graphlets)   | 67.33Â±1.02          | 55.42Â±5.13            | 74.92Â±0.82             | 72.39Â±1.94             | **ðŸ¥‡ 78.79Â±0.55**      | **ðŸ¥‡ 91.18Â±0.22**        | 90.61Â±1.05 ðŸ¥‰          | 92.98Â±0.20             | **ðŸ¥‡ 92.86Â±1.05**        |
|           | NSGNN-F&nbsp;(+MND+CC)      | **ðŸ¥‰ 68.35Â±0.46**   | 77.58Â±1.27            | **ðŸ¥‡ 78.54Â±0.90**      | **ðŸ¥‡ 81.38Â±0.63**      | **ðŸ¥‰ 72.96Â±0.43**      | **ðŸ¥ˆ 90.45Â±0.30**        | **ðŸ¥ˆ 91.59Â±0.58**      | **ðŸ¥‰ 93.42Â±0.79**      | **ðŸ¥‰ 86.62Â±1.30**        |
|           | NSGNN-S&nbsp;(+RW)          | **ðŸ¥ˆ 69.56Â±1.43**   | **ðŸ¥ˆ 80.97Â±0.22**     | **ðŸ¥‰ 76.51Â±0.81**      | 77.65Â±0.52             | 59.40Â±0.78             | 89.59Â±1.10              | 86.15Â±0.56             | **ðŸ¥‡ 93.67Â±0.27**      | 84.54Â±0.38             |
|           | NSGNN-S&nbsp;(+Graphlets)   | 66.83Â±1.27          | 73.30Â±0.30            | 54.79Â±2.51             | 72.58Â±0.79             | 46.14Â±3.84             | 87.67Â±1.66              | 85.88Â±0.38             | 89.90Â±0.57             | 82.52Â±0.99             |
|           | NSGNN-S&nbsp;(+MND+CC)      | 67.45Â±0.57          | **ðŸ¥‰ 80.02Â±0.66**     | 73.19Â±0.61             | **ðŸ¥‰ 77.75Â±0.94**      | 54.12Â±1.40             | 87.72Â±0.90              | 89.98Â±1.22             | 91.25Â±0.62             | 71.83Â±0.40             |
